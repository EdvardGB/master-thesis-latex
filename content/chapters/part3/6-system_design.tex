%% System Design
%%=========================================

\chapter{System Design}
\label{ch:system_design}
The main objective of this thesis is to answer the research questions by creating a system, as established in Chapter \ref{ch:methodology} by our choice of research strategy. In this chapter we present the design of the system we made. 

%%=========================================

\section{General Design}
Our models, presented in Chapter \ref{ch:models}, uses supervised learning, a task which revolves around two phases; training and testing. Our system was design specifically with this in mind.

The system consists of several separate modules, each responsible for its own task. The two first modules are the {\tt Trainer} and the {\tt Tester}. These two modules were responsible for either training, or testing, a model on a dataset. These modules were responsible for starting whatever other modules were required to run before the actual training or testing could take place. The {\tt Preprocessor} was responsible for creating the datasets we use in both the training and testing phase. This module is further explained in Section \ref{sec:preprocessor}. The {\tt Transformator} module ``transformed" the input and label data stored from the {\tt Preprocessor} into a format that the models expected. This process is explained in Section yy. Finally, the system calls the {\tt Predictor} which loads the correct model and either starts training or testing it.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{fig/system_design/system_design.png}
    \caption{Simplified system design}
    \label{fig:system-design}
\end{figure}

Figure \ref{fig:system-design} presents a simplified overview of the system design, and how the modules fit together. A whole line indicates a direct route from one module to another, and a dashed line indicates that the module can take one of several routes. For example can the {\tt Trainer} either call the {\tt Preprocessor} to create a new dataset, or it may call the {\tt Transformator} directly if it is asked to reuse an existing dataset.

%%=========================================

\section{Preprocessor}
\label{sec:preprocessor}
As there exists no datasets suitable for our particular problem, we decided to create these ourselves. Creation of the datasets were done by implementing a configurable pipeline system that involved processing over several steps:

\begin{enumerate}
    \item Build a complete dictionary of words, make sure they only include allowed characters.
    \item Select random words from the list and construct training, validation, and test sets. Make sure no words are picked that exceeds the maximum word length configuration. Remove duplicated words both across lists, and within the same list as per configured.
    \item Using an image library, write the text from the lists on individual (empty) canvases, with the specified font type and font size.
    \item Find the boundaries of the characters and crop the text to remove the excess space on the canvas.
    \item As configured, apply the masks and extract the signature values.
    \item Save the final output for later usage.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{fig/development_process/pipeline.pdf}
    \caption{Illustration of pipeline process from canvas to signature}
    \label{fig:development-pipeline}
\end{figure}

Figure \ref{fig:development-pipeline} illustrates the steps done when writing out, cropping, and applying our signature to a word. First we write out the word on a big, white canvas. This canvas has a predefined size, as we are unable to predict the actual size of text before it is written out with our image library. The canvas is then cropped based on the boundaries calculated from the individual characters. Finally, we apply the signature to the cropped image and extract the pixels. In Figure \ref{fig:development-pipeline}, the rightmost subfigure illustrates the extracted signature from the middle subfigure, which has a height of one pixels and is masked fourteen pixels from the bottom. The signature was expanded vertically for increased visibility. The final signature sequence is extracted by iterating over the pixels in the image, and is stored for later. The word ``AMPLITUDES" results here in a signature sequence that is 207 pixels long.

%%=========================================

\section{Transformator}
The {\tt Transformator} module was created to transform the sequences of binary data from the {\tt Preprocessor} into a format that the models expected. During development, especially in the early stages, the formats the models expected their inputs and output varied. It therefore made sense to split the {\tt Preprocessor} and the {\tt Transformator} into separate modules which were ran in sequence. This allowed us to reuse the same dataset on multiple models that had different input and output format expectations.

The {\tt Transformator} was given a sequence of ``handlers", depending on which model was to be loaded in the {\tt Predictor}. These handlers were executed in sequence, and each handler did a modification to either the input or the output format, and the data was propagated to the next handler. This way, the handlers could easily be reordered or swapped if a model expected another format. Typical tasks included padding the input to a given width, rescaling the input to whole integers, or turning the output into a one-hot matrix.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{fig/development_process/transformator.png}
    \caption{Illustration of handlers transforming data}
    \label{fig:development-transformator}
\end{figure}

Figure \ref{fig:development-transformator} illustrates a sequence of handlers, each transforming the data in one specific way. The first handler initiates the data by loading the binary data from the {\tt Preprocessor}. The second handler concatenates the binary data into sequences, where positive integers indicates a series of white pixels, and a negative integer indicates a series of black pixels. The third handler applies padding, to ensure that all the data has the same width before feeding it to the models. The padding is done by appending zeros at the end of the original sequence. The second last handler re-indexes the data, as our models expect whole integer values. The final handler transforms the labels from letters to a integer value, here we have given each letter the value that corresponds to their number in the English alphabet.