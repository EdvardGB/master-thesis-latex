%% Problem elaboration
%%=========================================

\chapter{Problem Elaboration}
\label{ch:problem}
In this chapter, we will expand on the problem definition given in the introduction chapter. In Section \ref{sec:tuning_input_data} we explain how the use of signatures allows us to tune the input data. We explain how the use of different typefaces and typography techniques may affect our problem in Section \ref{sec:use_of_fonts}. We explain how our problem has to deal with ambiguous data in Section \ref{sec:ambiguous_input}. Input and output is evaluated in context of each other in Section \ref{sec:evaluating_problem_input_and_output}, and in Section \ref{sec:translation} we evaluate our problem as a type of translation task.

%%=========================================

\section{Tuning Input Data}
\label{sec:tuning_input_data}
With the use of signatures, we can alter how we capture the data from the original image in various ways. These alterations can be done by configuring text sizes, signature positions, or signature heights in different ways. Altering the signature capturing configurations would result in completely new sequences for words.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{fig/chapter2/signature_multiple.png}
    \caption{The word ``CAT'' with two signatures at different heights}
    \label{fig:thesis-signature-comparison}
\end{figure}

Let us consider the word ``CAT'' in upper-case letters, written in Arial with a font height of 50 pixels, as illustrated in Figure \ref{fig:thesis-signature-comparison}. In this figure, we have highlighted two signatures, both with a height of one pixel. The first signature is 16 pixels from the bottom, while the other is five pixels from the top. As we can see from the illustration, the signatures we capture from the text varies significantly depending on where we chose to place it. For example, the top signature defines a T as 38 black pixels, while the bottom defines it as seven black pixels.

Figure \ref{fig:thesis-signature-comparison} also illustrates how our system needs to differentiate between letter spacing and characters that consist of multiple strokes. In the bottom signature, the letter C is defined as a sequence of eight black, 27 white, and seven black pixels. However, the sequence of seven black, seven white and 35 black pixels is just the final stroke of the letter C as well as the letter A including the space between the two letters. This sequence should not be classified as a letter, as it contains fragments of two separate ones.

%%=========================================

\section{Typefaces and Typography Techniques}
\label{sec:use_of_fonts}
In this section, we look closer at how typefaces (also known as font family), and techniques in typography may affect our problem.

\subsection{Typefaces}
\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{fig/chapter2/typeface_comparison.png}
    \caption{The word ``CAT'' written in Arial and Times New Roman with highlighted serifs}
    \label{fig:typeface-comparison}
\end{figure}

In addition to tuning the capturing of the input data, choice of fonts may also play a role in the ambiguity of the problem. In Figure \ref{fig:thesis-signature-comparison} we have used the monoline sans-serif font Arial. Monoline means that all the strokes in the typeface have the same widths. Sans-serif means that the font does not have serifs; a crossing feature at the end of the principal character strokes \citep{felici2011complete}. In Figure \ref{fig:typeface-comparison} we have written the word ``CAT'' first in Arial, and then in Times New Roman. Times New Roman is a font with serifs which is not monoline. The serifs are highlighted in red in the figure. The visual difference between the two words illustrates how the choice of font affects the captured sequences.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{fig/chapter2/regular_mono_comparison.png}
    \caption{Text with a variable-width font on the left, and monospace on the right}
    \label{fig:regular-mono-comparison}
\end{figure}

Fonts are also spaced differently. A monospaced font, also called fixed-width font, uses the same width for all characters. This is in contrast to variable-width fonts, where each character may have different widths \citep{felici2011complete}. Illustrated in Figure \ref{fig:regular-mono-comparison}, the text on the left is written in regular Arial which has variable width characters, while the text on the right is written in an Arial variant with monospacing. The two words written in monospaced font have equal width, whereas the two words that are written in a variable-width font have different widths. With a monospaced font, each glyph is placed inside a maximum width constraint. The glyph does not need to take up the entire width, but monospacing guarantees that there are no strokes outside the constraint. In our problem, we do not define where a character ``starts'' or ``stops'', so we do not know the location of these constraints. However, the use of a variable-width font may give increased variance in the distances between two glyphs.

\subsection{Typography Techniques}
\label{sec:other_factors}
There are additional factors affects how text looks, which may, in turn, affect the characteristics of the captured sequences. Kerning is one such factor. Kerning is the process of adjusting the spacing between two characters to compensate for their relative shapes. This is done to increase the readability and create a more visually pleasing result \citep{felici2011complete}. An illustrative example of kerning can be seen in Figure \ref{fig:kerning-comparison}, where the letters on the left side have applied kerning, bringing the two letters closer. The letters on the right side have no kerning. On the left side, the letters more naturally fit against each other, while the letters on the right side have a conspicuous spacing between them. As for our problem, kerning may make it more difficult to separate the characters from each other. Because kerning eliminates long sequences of spacing, by shifting characters closer to each other, it eliminates ``hints'' that could otherwise be used to identify where one letter ends and another begins.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{fig/chapter2/kerning.png}
    \caption{Kerning adjusted text on the left, no kerning on the right}
    \label{fig:kerning-comparison}
\end{figure}

Other techniques exist in typography that is applied to text to achieve more readable and visually pleasing arrangement of characters. As these alter how the text looks, it may alter our input data. Some of these are \citep{felici2011complete}:

\begin{itemize}
    \item Typographic alignments, such as justified text or ragged right.
    \item Font weights, which defines the degree of boldness and widths of strokes.
    \item Slanted forms such as italic.
    \item Location of the baseline, which defines the line that most of the characters appear to be sitting on.
    \item Anti-aliasing or font smoothing, which is a technique to smoothing the appearance of characters on a computer screen by adding gray pixels around their edges.
\end{itemize}

%%=========================================

\section{Ambiguous Input}
\label{sec:ambiguous_input}
There is a chance our input data may end up being ambiguous. A character signature can consist of a single sequence of black pixels or a series of alternating black and white pixels. Because our system does not know what a character looks like, there is no way for it to know what sequences are ``rests'' of characters, spacing, or valid characters. It may also happen that a character consisting of a single sequence of black pixels is also a subset of another character. 

Consider the bottom signature in Figure \ref{fig:thesis-signature-comparison}. Because Arial is monolinear, we know that the strokes on the C and the T have equal width. The T could be represented as a series of some white pixels, three black pixels, and optionally more white pixels. We can not know for sure just how many white pixels is before and after the three black pixels, because this may vary depending on what character is before and after the T (if any). Now, if our system learns this mapping, it will incorrectly recognize various other characters, such as parts of the C as a potential T. This means that our system has to learn the recognize a huge variety of sequences and correctly map them to an output character while ignoring invalid sequences.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
        \hline 
        \textbf{Character(s)} & \textbf{Signature}                                    & \textbf{Sequence}            \\ \hline
        A                     & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\)             & \(3B, 7W, 3B\)                 \\ \hline
        B                     & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\)       & \(3B, 7W, 5B\)                 \\ \hline
        C, I, J, L, T and Y   & \([0, 0, 0]\)                                           & \(3B\)                         \\ \hline
        D                     & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\)    & \(3B, 10W, 3B\)                \\ \hline
        E and F               & \([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\)          & \(14B\)                        \\ \hline
        G                     & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\) & \(3B, 6W, 7B\)                 \\ \hline
        H and U               & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\)       & \(3B, 9W, 3B\)                 \\ \hline
        K                     & \([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\)                      & \(5B, 1W, 4B\)                 \\ \hline
        M                     & \([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\)       & \(3B, 4W, 1B, 4W, 3B\)         \\ \hline
        N                     & \([0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0]\)       & \(3B, 4W, 3B, 2W, 3B\)         \\ \hline
        O and Q               & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\) & \(3B, 11W, 3B\)                \\ \hline
        P                     & \([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\)             & \(13B\)                        \\ \hline
        R                     & \([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\)                      & \(10B\)                        \\ \hline
        S and X               & \([0, 0, 0, 0, 0, 0, 0]\)                               & \(7B\)                         \\ \hline
        V                     & \([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]\)                   & \(4B, 4W, 3B\)                 \\ \hline
        W                     & \([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\) & \(3B, 3W, 2B, 1W, 3B, 2W, 3B\) \\ \hline
        Z                     & \([0, 0, 0, 0]\)                                        & \(4B\)                         \\ \hline
    \end{tabular}
    \captionsetup{justification=centering}
    \caption{Example of signatures and sequences of the upper-case letters in the English alphabet}
    \label{table:signature_sequence_example}
\end{table}

Table \ref{table:signature_sequence_example} holds the actual signatures and sequences for monospaced Arial given the settings specified in Section \ref{sec:goals_and_research_questions}. This table illustrates how the input is encoded and what our system has to recognize and learn. We can see examples of why it may be difficult in the sequences for the letters C, I, J, L, T, and Y. These six letters all share the same sequence. With an identical sequence, the only way we can differentiate between them is to consider the white pixels before and after the three black pixels. Many of the other character sequences besides the ones for C, I, J, L, T, and Y also contains three black pixels after each other. In total, the subsequence of three black pixels is found in eleven of the seventeen unique character sequences. Some of them, like W and N, also contains three subsequent black pixels multiple times in their sequences. 

The sequences in this table are just the sequences that correspond to separate characters. Once we have multiple characters after each other, with the natural spacing between them, many new sequences also have to be considered. 

This all boils down to the fact that the complete sequences of words may have many repeated subsequences, where some of them are individual letters, while other are parts of multiple letters. This substantiates that correctly recognizing letters in words using signatures is a difficult problem that requires a system that can learn beyond simply recognizing parts of sequences.

%%=========================================

\section{Evaluating Problem Input and Output}
\label{sec:evaluating_problem_input_and_output}
In our problem, we have an input that is a matrix or a vector of binary data. The binary input denotes the color of a particular pixel at the given location in our ``signature''. The output, or the correct labels, will correspond to the correct letter in the word. For convenience, the letters will be given a unique integer value. For example, if the words are written in upper-cased letters of the English language, we could use the numbers in the range 1 to 26, denoting A through Z.

\begin{figure}[h]
    \renewcommand\figurename{Example}
    \begin{equation*}
        \begin{aligned}
           \vec{\text{inputRaw}}               &= \lbrack 4W, 3B, 7W, 3B, 8W, 3B, 18W, 3B, 23W, 3B, 13W, 14B, 6W, 3B, 10W, 3B \rbrack \\
           \vec{\text{inputEncoded}}           &= \lbrack 4, -3, 7, -3, 8, -3, 18, -3, 23, -3, 13, -14, 6, -3, 10, -3 \rbrack \\
           \vec{\text{outputEncoded}}          &= \lbrack 1, 12, 12, 9, 5, 4 \rbrack \\
           \text{output}                       &= \text{ALLIED}
        \end{aligned}
    \end{equation*}
    \caption{Input and output example}
    \label{eq:input_output_example}
\end{figure}

Example \ref{eq:input_output_example} contains actual input and output for the word ``ALLIED''. Note that in this example, we have encoded the input to integers. We did this by negating the lengths of sequences of black pixels. With this encoding four black pixels are encoded as -4. Similarity, sequences of white pixels were not altered, meaning a sequence of 18 white pixels is encoded as 18.

\subsection{Input Format}
Our input has the feature that they form a sequence. Both the values in the sequence and the ordering of the sequence is crucial for the prediction. This feature is fundamentally different from other problems such as traditional image recognition, where the exact location of a pattern may be irrelevant.

Because the input forms a sequence, it is important that the entire sequence is read, and that we do not cut the sequence off at the end, removing important information that we need. Truncating or ignoring values in the input sequence would result in mislearning. Instead of our model correctly identify subsequences, the model would attempt to find patters in the data that is not there. This mislearning would cripple the model, and the overall accuracy may suffer due to contradicting sequences. Keeping the input data unaltered and complete is therefore essential.

\begin{figure}[h]
    \renewcommand\figurename{Example}
    \begin{equation*}
        \begin{aligned}
           \vec{\text{inputEncoded}}                &= \lbrack -3, \pi, 23, -3, \pi, 13, -14, \pi \rbrack \\
           \vec{\text{outputEncoded}}               &= \lbrack 12, 9, 5 \rbrack \\
           \text{output}                            &= \text{LIE}
        \end{aligned}
    \end{equation*}
    \caption{Input with stop words}
    \label{eq:input_stop_words}
\end{figure}

We lack the concept of ``stop words'' in our problem. Example \ref{eq:input_stop_words} illustrates an input with stop words, denoted as $\pi$. Stop words may make the problem easier to solve, as we would know within which boundaries each character resides. In Example \ref{eq:input_stop_words}, we have placed the stop word right after the end of each character, instead of just the barriers of the character itself. These barriers could potentially reduce ambiguity as we would know for a fact that the letter I if followed by an E, would always be the subsequence \([23, -3]\). However, instead of relying on stop words, we want our model to find a pattern in the input that makes sense based on the corresponding output. This pattern, if correctly predicted, would not need explicit stop words, as the model would be able to find them implicitly.

\subsection{Output Format}
As with the input, our output also forms a sequence. Both the values in the sequence and the ordering of the sequence is important. The words ``HELLO'' and ``HLLOE'' contains the same letters, but have different meanings. This difference illustrates that both the individual letters, as well as their arrangement are crucial to the problem and to learn the problem properly. 

%%=========================================

\section{Translation}
\label{sec:translation}
We have now considered the input and output separately. Considering the input and output in the context of each other, we can see the relationship between the two. Sequences and subsequences in the input result in either an output sequence or a single output value. We can look at this process as a type of translation. We ``translate'' the input sequences of language \(\alpha\) into an output sequence of language \(\beta\). It is irrelevant that the actual input and output are not defined languages with linguistic properties. As long as there is a relationship between the source and target languages, the task may be considered as a translation problem. Figure \ref{fig:number_translation} illustrates the translation between our source and target languages, reusing the data from Example \ref{eq:input_stop_words}. The values in the translated language are the same as the encoded output in Example \ref{eq:input_stop_words}, that is, the index value for each letter in the English language, where A is 1, B is 2 and so on.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{fig/background_theory/number_translation.png}
    \caption{Illustrative translation between our two languages}
    \label{fig:number_translation}
\end{figure}

\subsection{Dissimilarities to Typical Translation Problems}
While our problem may be similar to that of translation, it also differs in several ways. Common for almost all of these differences is that our languages are very simple. This difference means that we can simplify, or completely ignore, tasks that are otherwise important in more complex translation problems. For example, the task of ``part-of-speech tagging'' is to determine the part of speech for each word in sentences. This means to determine if a word is a noun, verb, adjective, and so on. ``Part-of-speech tagging'' is a complex task and a task that is important, as it may influence how words are used in different contexts. In our constructed languages, we have no concept of such speech groups. Our ``words'' have one, and only one, meaning, regardless of context. 

Our problem also differs from translation between two spoken words when it comes to arrangement and order. We know that with our two ``languages'', the ordering is always the same, going from left to right. Translating spoken languages can never give the same guarantee, as different languages have different sentence structures. Words that can be directly translated from one language to another do not necessarily have the same arrangement in both of them.

These observations make it clear that although our problem is related to translation, it also differs from more traditional problems. 