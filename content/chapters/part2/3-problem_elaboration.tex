%% Problem elaboration
%%=========================================

\chapter{Problem Elaboration}
\label{ch:problem}
In this chapter, we will expand on the problem definition given in the introduction. In Section \ref{sec:tuning_input_data} we explain how the use of signatures allows us to tune the input data. We explain how different typefaces and typography techniques may affect our problem in Section \ref{sec:use_of_fonts}. How our problem has to deal with ambiguous data is explained in Section \ref{sec:ambiguous_input}. Input and output are evaluated in the context of each other in Section \ref{sec:evaluating_problem_input_and_output}, and in Section \ref{sec:translation} we evaluate our problem as a type of translation task. Finally, in Section \ref{sec:method}, we present our method for solving the problem.

%%=========================================

\section{Tuning Input Data}
\label{sec:tuning_input_data}
With the use of signatures, we can alter how we capture the data from the original image in various ways. These alterations can be done by configuring text sizes, signature positions, or signature heights in different ways. Altering the signature capturing configurations would result in completely new sequences for words.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{fig/chapter2/signature_multiple.png}
    \caption{The word ``CAT'' with two different signatures}
    \label{fig:thesis-signature-comparison}
\end{figure}

Let us consider the word ``CAT'' in upper-case letters, written in Arial with a font height of 50 pixels, as illustrated in Figure \ref{fig:thesis-signature-comparison}. In this figure, we have highlighted two signatures, both with a height of one pixel. The first signature is 16 pixels from the bottom, while the other is five pixels from the top. As we can see from the figure, the signatures we capture from the text varies significantly depending on where we chose to place it. For example, the top signature defines a T as 38 black pixels, while the bottom defines it as seven black pixels.

Figure \ref{fig:thesis-signature-comparison} also illustrates how our system needs to differentiate between letter spacing and characters that consist of multiple strokes. In the bottom signature, the letter C is defined as a sequence of eight black, 27 white, and seven black pixels. However, the sequence of seven black, seven white and 35 black pixels is just the final stroke of the letter C as well as the letter A. This sequence should not be classified as a letter, as it contains fragments of two separate ones.

%%=========================================

\section{Typefaces and Typography Techniques}
\label{sec:use_of_fonts}
In this section, we look closer at how typefaces (also known as font family), and techniques in typography may affect our problem.

\subsection{Typefaces}
In addition to tuning the capturing of the input data, choice of fonts may also play a role in the ambiguity of the problem. In Figure \ref{fig:thesis-signature-comparison} we used the monoline sans-serif font Arial. Monoline means that all the strokes in the typeface have the same widths. Sans-serif means that the font does not have serifs; a crossing feature at the end of the principal character strokes \citep[pp.~33--36]{felici2011complete}. In Figure \ref{fig:typeface-comparison} we have written the word ``CAT'' first in Arial, and then in Times New Roman. Times New Roman is a font with serifs which is not monoline. The serifs are highlighted in red in the figure. The visual difference between the two words illustrates how the choice of font affects the captured sequences.

\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}
    \includegraphics[width=1.0\textwidth]{fig/chapter2/typeface_comparison.png}
    \caption{The word ``CAT'' written in Arial and Times New Roman with highlighted serifs}
    \label{fig:typeface-comparison}
\end{figure}

Fonts are also spaced differently. A monospaced font, also called fixed-width font, uses the same width for all characters. This is in contrast to variable-width fonts, where each character may have different widths \citep[pp.~8--11]{felici2011complete}. Illustrated in Figure \ref{fig:regular-mono-comparison}, the text on the left is written in regular Arial which has variable width characters, while the text on the right is written in an Arial variant with monospacing. The two words written in monospaced font have equal width, whereas the two words that are written in a variable-width font have different widths. With a monospaced font, each glyph is placed inside a maximum width constraint. The glyph does not need to take up the entire width, but monospacing guarantees that there are no strokes outside the constraint. In our problem, we do not define where a character ``starts'' or ``stops,'' so we do not know the location of these constraints. However, the use of a variable-width font may give increased variance in the distances between two glyphs.

\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}
    \includegraphics[width=1.0\textwidth]{fig/chapter2/regular_mono_comparison.png}
    \caption{Text with a variable-width font on the left, and a monospace type font on the right}
    \label{fig:regular-mono-comparison}
\end{figure}

\subsection{Typography Techniques}
\label{sec:other_factors}
There are additional factors that affects how text looks, which may, in turn, affect the characteristics of the captured sequences. Kerning is one such factor. Kerning is the process of adjusting the spacing between two characters to compensate for their relative shapes. This is done to increase the readability and create a more visually pleasing result \citep[chapt.~11]{felici2011complete}. An illustrative example of kerning can be seen in Figure \ref{fig:kerning-comparison}, where the letters on the left side have applied kerning, bringing the two letters closer. The letters on the right side have no kerning. On the left side, the letters more naturally fit against each other, while the letters on the right side have a conspicuous spacing between them. As for our problem, kerning may make it more difficult to separate the characters from each other. Because kerning eliminates long sequences of spacing, by shifting characters closer to each other, it eliminates ``hints'' that could otherwise be used to identify where one letter ends and another begins.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{fig/chapter2/kerning.png}
    \caption{Kerning adjusted text on the left, no kerning on the right}
    \label{fig:kerning-comparison}
\end{figure}

Other techniques exist in typography that are applied to text to achieve more readable and visually pleasing arrangement of characters. As these alter how the text looks, it may alter our input data. Some of these are \citep[pp.~320,~299,~302,~298,~297]{felici2011complete}:

\begin{itemize}
    \item Typographic alignments, such as justified text or ragged right.
    \item Font weights, which defines the degree of boldness and widths of strokes.
    \item Slanted forms such as italic.
    \item Location of the baseline, which defines the line that most of the characters appear to be sitting on.
    \item Anti-aliasing or font smoothing, which is a technique for smoothing the appearance of characters on a computer screen by adding gray pixels around their edges.
\end{itemize}

%%=========================================

\section{Ambiguous Input}
\label{sec:ambiguous_input}
There is a chance our input data may end up being ambiguous. A character signature can consist of a single sequence of black pixels or a series of alternating black and white pixels. Because our system does not know what a character looks like, there is no way for it to know what sequences are ``rests'' of characters, spacing, or valid characters. It may also happen that a character consisting of a single sequence of black pixels is also a subset of another character. 

Consider the bottom signature in Figure \ref{fig:thesis-signature-comparison}. Because Arial is a monolinear font, we know that the strokes on the C and the strokes on the T have equal width. The T could be represented as a series of some white pixels, three black pixels, and optionally more white pixels. We can not know for sure just how many white pixels is before or after the three consecutive black pixels, because this may vary depending on what character is before and after the T. If our system learns this mapping, it will incorrectly recognize various other characters, such as parts of the C as a potential T. This means that our system have to recognize a huge variety of sequences and correctly map them to an output character while ignoring invalid sequences.

\begin{table}[ht]
    \centering
    \begin{tabular}{|l|l|l|}
        \hline 
        \textbf{Character(s)} & \textbf{Signature}                                    & \textbf{Sequence}            \\ \hline
        A                     & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\)             & \(3B, 7W, 3B\)                 \\ \hline
        B                     & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\)       & \(3B, 7W, 5B\)                 \\ \hline
        C, I, J, L, T and Y   & \([0, 0, 0]\)                                           & \(3B\)                         \\ \hline
        D                     & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\)    & \(3B, 10W, 3B\)                \\ \hline
        E and F               & \([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\)          & \(14B\)                        \\ \hline
        G                     & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\) & \(3B, 6W, 7B\)                 \\ \hline
        H and U               & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\)       & \(3B, 9W, 3B\)                 \\ \hline
        K                     & \([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\)                      & \(5B, 1W, 4B\)                 \\ \hline
        M                     & \([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\)       & \(3B, 4W, 1B, 4W, 3B\)         \\ \hline
        N                     & \([0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0]\)       & \(3B, 4W, 3B, 2W, 3B\)         \\ \hline
        O and Q               & \([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\) & \(3B, 11W, 3B\)                \\ \hline
        P                     & \([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\)             & \(13B\)                        \\ \hline
        R                     & \([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\)                      & \(10B\)                        \\ \hline
        S and X               & \([0, 0, 0, 0, 0, 0, 0]\)                               & \(7B\)                         \\ \hline
        V                     & \([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]\)                   & \(4B, 4W, 3B\)                 \\ \hline
        W                     & \([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\) & \(3B, 3W, 2B, 1W, 3B, 2W, 3B\) \\ \hline
        Z                     & \([0, 0, 0, 0]\)                                        & \(4B\)                         \\ \hline
    \end{tabular}
    \captionsetup{justification=centering}
    \caption{Example of signatures and sequences of the upper-case letters in the English alphabet}
    \label{table:signature_sequence_example}
\end{table}

Table \ref{table:signature_sequence_example} holds the actual signatures and sequences for monospaced Arial given the settings specified in Section \ref{sec:goals_and_research_questions}. This table illustrates how the input is encoded and what our system has to recognize and learn. We can see examples of why the problem may be difficult in the sequences for the letters C, I, J, L, T, and Y. These six letters all share the same identical sequence. With an identical sequence, the only way we can differentiate between these letters is to consider the white pixels before and after its signature. Many of the other character sequences besides the ones for C, I, J, L, T, and Y also contains three consecutive black pixels. In total, the subsequence of three consecutive black pixels is found in eleven of the seventeen unique character sequences. Some of them, like W and N, also contains three subsequent black pixels multiple times in their sequences. 

Similarity, sequences for complete words will also consist of repeated subsequences. Some of these subsequences may be individual letters, while others are parts of multiple ones. This substantiates that our problem requires a system that can learn beyond simply mapping parts of sequences to sets of labels.

%%=========================================

\section{Evaluating Problem Input and Output}
\label{sec:evaluating_problem_input_and_output}
In our problem, we have an input that is a matrix or a vector of binary data. The binary input denotes the color of a particular pixel at the given location in our ``signature.'' The output, or the correct labels, will correspond to the correct letter in the word. For convenience, the letters will be given a unique integer value. For example, if the words are written in upper-case letters of the English language, we could use the numbers in the range 1 to 26, denoting A through Z.

\begin{figure}[ht]
    \renewcommand\figurename{Example}
    \begin{equation*}
        \begin{aligned}
           \vec{\text{inputRaw}}               &= \lbrack 4W, 3B, 7W, 3B, 8W, 3B, 18W, 3B, 23W, 3B, 13W, 14B, 6W, 3B, 10W, 3B \rbrack \\
           \vec{\text{inputEncoded}}           &= \lbrack 4, -3, 7, -3, 8, -3, 18, -3, 23, -3, 13, -14, 6, -3, 10, -3 \rbrack \\
           \vec{\text{outputEncoded}}          &= \lbrack 1, 12, 12, 9, 5, 4 \rbrack \\
           \text{output}                       &= \text{ALLIED}
        \end{aligned}
    \end{equation*}
    \caption{Input and output example}
    \label{eq:input_output_example}
\end{figure}

Example \ref{eq:input_output_example} contains actual input and output for the word ``ALLIED.'' Note that in this example, we have encoded the input to integers. This was done by counting the length of consecutive pixels of the same color. Consecutive black pixels are negated, to differentiate between sequences of black pixels and sequences of white pixels. With this encoding, four black consecutive pixels are encoded as -4. Similarity, a sequence of 18 consecutive white pixels is encoded as 18.

\subsection{Input Format}
Our input has the feature that they form a sequence. Both the values in the sequence, as well as the ordering of the sequence, is crucial for the prediction. This feature is fundamentally different from other problems such as traditional image recognition, where the exact location of a pattern may be irrelevant.

Because the input forms a sequence, it is important that the entire sequence is read, and that we do not cut the sequence off at the end. Truncating or ignoring values in the input sequence would result in mislearning. Instead of our model correctly identify subsequences, the model would attempt to find patters in the data that is not there. This mislearning would cripple the model, and the overall accuracy may suffer due to contradicting sequences. Keeping the input data unaltered and complete is therefore essential.

\begin{figure}[ht]
    \renewcommand\figurename{Example}
    \begin{equation*}
        \begin{aligned}
           \vec{\text{inputEncoded}}                &= \lbrack -3, \pi, 23, -3, \pi, 13, -14, \pi \rbrack \\
           \vec{\text{outputEncoded}}               &= \lbrack 12, 9, 5 \rbrack \\
           \text{output}                            &= \text{LIE}
        \end{aligned}
    \end{equation*}
    \caption{Input with stop words}
    \label{eq:input_stop_words}
\end{figure}

We lack the concept of ``stop words'' in our problem. Example \ref{eq:input_stop_words} illustrates an input with stop words, denoted as $\pi$. Stop words may make the problem easier to solve, as we would know within which boundaries each character resides. In Example \ref{eq:input_stop_words}, we have placed the stop word right after the end of each character, instead of just the barriers of the character itself. These barriers could potentially reduce ambiguity as we would know for a fact that the letter I if followed by an E, would always be the subsequence \([23, -3]\). However, instead of relying on stop words, we want our model to find a pattern in the input that makes sense based on the corresponding output. This pattern, if correctly predicted, would not need explicit stop words, as the model would be able to find them implicitly.

\subsection{Output Format}
As with the input, our output also forms a sequence. Both the values in the sequence and the ordering of the sequence itself is important. The words ``HELLO'' and ``HLLOE'' contains the same letters, but have different meanings.

%%=========================================

\section{Translation}
\label{sec:translation}
We have now considered the input and output separately. Considering the input and output in the context of each other, we can see the relationship between the two. Sequences and subsequences in the input result in either an output sequence or a single output value. This process can be seen as a type of translation. We ``translate'' the input sequences of language \(\alpha\) into an output sequence of language \(\beta\). It is irrelevant that the actual input and output are not defined languages with linguistic properties. As long as there is a relationship between the source and target languages, the task may be considered as a translation problem. Figure \ref{fig:number_translation} illustrates the translation between our source and target languages, reusing the data from Example \ref{eq:input_stop_words}. The values in the translated language are the same as the encoded output in Example \ref{eq:input_stop_words}, that is, the index value for each letter in the English language, where A is 1, B is 2 and so on.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/background_theory/number_translation.png}
    \caption{Illustrative translation between our two languages}
    \label{fig:number_translation}
\end{figure}

\subsection{Dissimilarities to Typical Translation Problems}
While our problem may be similar to that of translation, it also differs in several ways. Common for almost all of these differences is that our languages are very simple. This difference means that we can simplify, or completely ignore, tasks that are otherwise important in more complex translation problems. For example, the task of ``part-of-speech tagging'' is to determine the part of speech for each word in a sentence. This means to determine if a word is a noun, verb, adjective, and so on. ``Part-of-speech tagging'' is a complex task and a task that is important, as it may influence how words are used in different contexts. In our constructed languages, we have no concept of such speech groups. Our ``words'' have one, and only one, meaning, regardless of context. 

Our problem also differs from translation between two spoken words when it comes to arrangement and order. We know that with our two languages, the ordering is always the same, going from left to right. Translating spoken languages can never give the same guarantee, as different languages have different sentence structures. Words that can be directly translated from one language to another do not necessarily have the same arrangement in both of them.

These observations make it clear that although our problem is related to translation, it also differs from more traditional problems. 

%%=========================================

\section{Method}
\label{sec:method}
We established in the previous section that the problem can be considered as a translation problem between two languages \(\alpha\) and \(\beta\). In language \(\beta\) we have some word \(W\). This word is encoded by running it through some function \(f_{1}(x) = y\), resulting some output \(U\) in our other language \(\alpha\). This output is the signature sequences. The process of encoding the original word \(W\) to the sequence \(U\) can be considered as a translation, from language \(\beta\) to \(\alpha\). Our goal is to take the output \(U\), run it through some other function \(f_{2}(x) = y\) which gives us the original word \(W\). This process is the translation in the opposite direction and can also be considered as decoding the encoded sequence. Both the encoding and decoding processes are illustrated in Figure \ref{fig:translation_illustration}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/background_theory/translation_illustrated.png}
    \caption{Encoding and decoding between our two languages}
    \label{fig:translation_illustration}
\end{figure}

Our encoding function is a deterministic algorithm, that is, given the same input, it will always produce the same output. The fact that the problem is deterministic makes it possible for us to verify a solution with absolute certainty, which is usually not the case with traditional translation problems. The nature of this encoding also makes the problem solvable in many ways. 

One way we could potentially solve the problem is by applying exhaustive search, also known as brute-force search. This technique involves enumerating all possible candidates for the solution and is guaranteed always to find a solution if it exists. The problem with this approach is the number of calculations necessary to find a solution. If we have a total of 26 classes, one class for each letter in the English alphabet, and we want to decode the signatures of a word that is 16 letters long, we end up with \(26^{16}\) possible combinations. This number makes it clear that exhaustive search approaches are not applicable to a problem like ours.

Instead of utilizing exhaustive search and brute-force methods, we want to find a way to solve the problem in a reasonable amount of time. A trade-off from this is that an optimal solution in many cases can not be guaranteed. We have focused on more general areas of machine learning to solve this problem, particularly the field of natural language processing and machine translation. The next two chapters present background theory and related work done in this and closely related fields.