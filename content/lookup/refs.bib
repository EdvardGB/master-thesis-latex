%% Bibtex file
%%=========================================

%%
%% This file contains all the bibtex entries for the entire thesis
%%

%% 1 - Introduction
%%=========================================

%% Minecraft changelog
@misc{misc-minecraft.172-changelog,
    author =       "{Official Minecraft Wiki}",
    title =        "1.7.2 - Official Minecraft Wiki",
    year =         "2017",
    howpublished = {\url{http://minecraft.gamepedia.com/1.7.2}},
    publisher =    "Gamepedia",
    note =         "[Accessed: 2017-04-20]"
}

%% General information about the industrial revolution and the information revolution
@book{freeman2001time,
    title =        "As time goes by: from the industrial revolutions to the information revolution",
    author =       "Freeman, Christopher and Lou{\c{c}}{\~a}, Francisco",
    year =         "2001",
    publisher =    "Oxford University Press"
}

%% Definition of digitization
@misc{misc-oed-digitization,
    author =       "{Oxford English Dictionary}",
    title =        "digitization",
    year =         "2010",
    howpublished = {\url{http://www.oed.com/view/Entry/240886}},
    publisher =    "Oxford English Dictionary",
    note =         "[Accessed: 2016-10-24]"
}

%% Information page for the digital library in Norway
@misc{misc-nb-digial-library,
    author =       "Nasjonalbiblioteket",
    year =         "2016",
    title =        "Collaboration Projects",
    howpublished = {\url{http://www.nb.no/English/The-Digital-Library/Collaboration-Projects}},
    publisher =    "Nasjonalbiblioteket",
    note =         "[Accessed: 2016-10-25]"
}

%% Gives a few examples of what we can do about digital storage (which possibilities it opens)
@article{lee2002state,
    title =        "The state of the art and practice in digital preservation",
    author =       "Lee, Kyong-Ho and Slattery, Oliver and Lu, Richang and Tang, Xiao and McCrary, Victor",
    journal =      "Journal of research of the National institute of standards and technology",
    volume =       "107",
    number =       "1",
    pages =        "93",
    year =         "2002",
    publisher =    "{National Institute of Standards and Technology}"
}

%% Mentions price and space of HDDs
@article{morris2003evolution,
    title =        "The evolution of storage systems",
    author =       "Morris, Robert JT and Truskowski, Brian J",
    journal =      "IBM systems Journal",
    volume =       "42",
    number =       "2",
    pages =        "205--217",
    year =         "2003",
    publisher =    "IBM"
}

%% Digitizaion of books. Google digitized for index searches
@article{coyle2006mass,
    title =        "Mass digitization of books",
    author =       "Coyle, Karen",
    journal =      "The Journal of Academic Librarianship",
    volume =       "32",
    number =       "6",
    pages =        "641--645",
    year =         "2006",
    publisher =    "Elsevier"
}

%% General talks of OCR and its part in AI
@book{mori1999optical,
    title =        "Optical character recognition",
    author =       "Mori, Shunji and Nishida, Hirobumi and Yamada, Hiromitsu",
    year =         "1999",
    publisher =    "John Wiley \& Sons, Inc."
}

%% US patent for OCR for blind people
@misc{kurzweil2000reading,
    title =        "Reading machine system for the blind having a dictionary",
    author =       "Kurzweil, Raymond C and Bhathena, Firdaus and Baum, Stephen R",
    year =         "2000",
    note =         "US Patent 6,033,224"
}

%% History of OCR, early research
@article{mori1992historical,
    title =        "Historical review of OCR research and development",
   author =        "Mori, Shunji and Suen, Ching Y and Yamamoto, Kazuhiko",
   journal =       "Proceedings of the IEEE",
   volume =        "80",
   number =        "7",
   pages =         "1029--1058",
   year =          "1992",
   publisher =     "IEEE"
}

%% Quote about current situations of OCR systems
@article{ye2015text,
    title =        "Text detection and recognition in imagery: A survey",
    author =       "Ye, Qixiang and Doermann, David",
    journal =      "IEEE transactions on pattern analysis and machine intelligence",
    volume =       "37",
    number =       "7",
    pages =        "1480--1500",
    year =         "2015",
    publisher =    "IEEE"
}

%% OCR and damaged documents
@article{bhardwaj2014imaging,
    title =        "An Imaging Technique for Retrieval of Lost Content in Damaged Documents",
    author =       "Bhardwaj, Neelam and Agarwal, Suneeta",
    journal =      "International Journal of Computer Applications",
    volume =       "104",
    number =       "5",
    year =         "2014",
    publisher =    "Foundation of Computer Science"
}

%% 2 - Methodology
%%=========================================

%% The research book used in some course at NTNU that basically the entire chapter is quoted from
@book{oates2005researching,
    title =        "Researching information systems and computing",
    author =       "Oates, Briony J",
    year =         "2005",
    publisher =    "Sage"
}

%% Explains types of IT products
@article{march1995design,
    title =        "Design and natural science research on information technology",
    author =       "March, Salvatore T and Smith, Gerald F",
    journal =      "Decision support systems",
    volume =       "15",
    number =       "4",
    pages =        "251--266",
    year =         "1995",
    publisher =    "Elsevier"
}

%% Explains some steps in the research approach
@article{vaishnavi2004design,
    title =        "Design research in information systems",
    author =       "Vaishnavi, Vijay and Kuechler, Bill",
    year =         "2004",
    journal =      "Association for Information Systems",
    note =         "\url{https://web.archive.org/web/20050208031622/http://www.isworld.org/Researchdesign/drisisworld.htm}"
}

%% 3 - Problem Elaboration
%%=========================================

%% Everything about typography
@book{felici2011complete,
    title =        "The complete manual of typography: a guide to setting perfect type",
    author =       "James W. Felici",
    year =         "2012",
    publisher =    "Peachpit Press ",
    isbn =         "9780321773265,0321773268",
    edition =      "2nd",
}

%% 4 - Background Theory
%%=========================================

%% LSTM Peephole
@article{gers2001lstm,
  title={LSTM recurrent networks learn simple context-free and context-sensitive languages},
  author={Gers, Felix A and Schmidhuber, E},
  journal={IEEE Transactions on Neural Networks},
  volume={12},
  number={6},
  pages={1333--1340},
  year={2001},
  publisher={IEEE}
}

%% Convolutional LSTM
@inproceedings{xingjian2015convolutional,
  title={Convolutional LSTM network: A machine learning approach for precipitation nowcasting},
  author={Xingjian, SHI and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-Kin and Woo, Wang-chun},
  booktitle={Advances in Neural Information Processing Systems},
  pages={802--810},
  year={2015}
}

%% Forget gate to LSTMs
@article{gers2000learning,
  title={Learning to forget: Continual prediction with LSTM},
  author={Gers, Felix A and Schmidhuber, J{\"u}rgen and Cummins, Fred},
  journal={Neural computation},
  volume={12},
  number={10},
  pages={2451--2471},
  year={2000},
  publisher={MIT Press}
}

%% Compared LSTMs
@article{greff2016lstm,
  title={LSTM: A search space odyssey},
  author={Greff, Klaus and Srivastava, Rupesh K and Koutn{\'\i}k, Jan and Steunebrink, Bas R and Schmidhuber, J{\"u}rgen},
  journal={IEEE transactions on neural networks and learning systems},
  year={2016},
  publisher={IEEE}
}

%% LSTM vs GRU
@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

%% LSTM vs GRU again
@inproceedings{jozefowicz2015empirical,
  title={An empirical exploration of recurrent network architectures},
  author={Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
  booktitle={Proceedings of the 32nd International Conference on Machine Learning (ICML-15)},
  pages={2342--2350},
  year={2015}
}

%% 5 - Related work
%%=========================================

%% Information on MT research and its history
@article{hutchins2007machine,
    title =        "Machine translation: A concise history",
    author =       "Hutchins, John",
    journal =      "Computer aided translation: Theory and practice",
    year =         "2007",
    publisher =    "Chinese University of Hong Kong"
}

%% History of NLP (mostly MT)
@article{hutchins1997first,
    title =        "From first conception to first demonstration: the nascent years of machine translation, 1947--1954. a chronology",
    author =       "Hutchins, John",
    journal =      "Machine Translation",
    volume =       "12",
    number =       "3",
    pages =        "195--252",
    year =         "1997",
    publisher =    "Springer"
}

%% ALPAC quote
@book{national1966language,
    title =        "Language and Machines: Computers in Translation and Linguistics; A Report",
    author =       "National Research Council and Automatic Language Processing Advisory Committee and others",
    year =         "1966",
    publisher =    "National Academy of Sciences, National Research Council"
}

%% Book about SMT. Used for general information and illustration
@book{koehn2010statistical,
    title =        "Statistical machine translation",
    author =       "Koehn, Philipp",
    year =         "2010",
    publisher =    "Cambridge University Press"
}

%% Blog entry Google about current state of Google Translate
@misc{turovsky2016googletranslate,
    author =       "Barak Turovsky",
    year =         "2016",
    title =        "Ten years of Google Translate",
    howpublished = {\url{https://blog.google/products/translate/ten-years-of-google-translate/}},
    publisher =    "Google",
    note =         "[Accessed: 2017-03-28]"
}

@misc{schuster2016googletranslate,
    author =       "Mike Schuster, Melvin Johnson and Nikhil Thorat",
    year =         "2016",
    title =        "Zero-Shot Translation with Google’s Multilingual Neural Machine Translation System",
    howpublished = {\url{https://research.googleblog.com/2016/11/zero-shot-translation-with-googles.html}},
    publisher =    "Google",
    note =         "[Accessed: 2017-05-12]"
}

%% General information about SMT
@article{brown1990statistical,
    title =        "A statistical approach to machine translation",
    author =       "Brown, Peter F and Cocke, John and Pietra, Stephen A Della and Pietra, Vincent J Della and Jelinek, Fredrick and Lafferty, John D and Mercer, Robert L and Roossin, Paul S",
    journal =      "Computational linguistics",
    volume =       "16",
    number =       "2",
    pages =        "79--85",
    year =         "1990",
    publisher =    "MIT Press"
}

%% General about NMT
@article{wolk2015neural,
    title =        "Neural-based machine translation for medical text domain. Based on European Medicines Agency leaflet texts",
    author =       "Wo{\l}k, Krzysztof and Marasek, Krzysztof",
    journal =      "Procedia Computer Science",
    volume =       "64",
    pages =        "2--9",
    year =         "2015",
    publisher =    "Elsevier"
}

%% Claim about SMTs being dominant in the previous decades + information about encoder/decoder
@article{wu2016google,
    title =        "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
    author =       "Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others",
    journal =      "arXiv preprint arXiv:1609.0814",
    year =         "2016"
}

%% Blog entry Google about NMT replacing SMT
@misc{turovsky2016googletranslatenmt,
    author =       "Barak Turovsky",
    year =         "2016",
    title =        "Found in translation: More accurate, fluent sentences in Google Translate",
    howpublished = {\url{https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/}},
    publisher =    "Google",
    note =         "[Accessed: 2017-03-28]"
}

%% State of the art SMT example
@inproceedings{watanabe07onlinelargemargin,
    author =       "Taro Watanabe and Jun Suzuki and Hajime Tsukada and Hideki Isozaki",
    title =        "Online large-margin training for statistical machine translation",
    booktitle =    "In Proc. of EMNLP",
    year =         "2007"
}

%% First real encoder-decoder implementation
@inproceedings{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={3104--3112},
  year={2014}
}

%% Encoder-decoder and CNN, first ever encoder-decoder
@inproceedings{kalchbrenner2013recurrent,
  title={Recurrent Continuous Translation Models.},
  author={Kalchbrenner, Nal and Blunsom, Phil},
  booktitle={EMNLP},
  volume={3},
  pages={413},
  year={2013}
}

%% First RNN encoder-decoder
@article{cho2014learning,
    title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
    author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
    journal={arXiv preprint arXiv:1406.1078},
    year={2014}
}

%% Encoder-decoder bi-RNN with GRU
@article{chung2016character,
  title={A character-level decoder without explicit segmentation for neural machine translation},
  author={Chung, Junyoung and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1603.06147},
  year={2016}
}

%% Encoder-decoder without fixed vector
@article{bahdanau2014neural,
    title={Neural machine translation by jointly learning to align and translate},
    author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
    journal={arXiv preprint arXiv:1409.0473},
    year={2014}
}

%% Artificial intelligence book. General neural network
@book{russell2010aimodernapproach,
   title =     {Artificial Intelligence: A Modern Approach},
   author =    {Stuart Russell, Peter Norvig},
   publisher = {Prentice Hall},
   isbn =      {0136042597, 9780136042594},
   year =      {2010},
   series =    {Prentice Hall Series in Artificial Intelligence},
   edition =   {3rd},
   volume =    {},
}

%% On RNNs
@article{rumelhart1988learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Cognitive modeling},
  volume={5},
  number={3},
  pages={1},
  year={1988}
}

%% Book about deep learning. RRN
@book{goodfellow2016deeplearning,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

%% Purposed LSTM
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

%% Back-propagation through time
@article{werbos1990backpropagation,
  title={Backpropagation through time: what it does and how to do it},
  author={Werbos, Paul J},
  journal={Proceedings of the IEEE},
  volume={78},
  number={10},
  pages={1550--1560},
  year={1990},
  publisher={IEEE}
}

%% Long-Term dependencies is difficult
@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}

%% LSTM information
@article{gers2002learning,
  title={Learning precise timing with LSTM recurrent networks},
  author={Gers, Felix A and Schraudolph, Nicol N and Schmidhuber, J{\"u}rgen},
  journal={Journal of machine learning research},
  volume={3},
  number={Aug},
  pages={115--143},
  year={2002}
}

%% Blog post about LSTM
@misc{olah2015lstm,
    author =       "Christopher Olah",
    year =         "2015",
    title =        "Understanding LSTM Networks",
    howpublished = {\url{http://colah.github.io/posts/2015-08-Understanding-LSTMs/}},
    note =         "[Accessed: 2017-03-30"
}

%% 7
@inproceedings{hinton1986learning,
  title={Learning distributed representations of concepts},
  author={Hinton, Geoffrey E},
  booktitle={Proceedings of the eighth annual conference of the cognitive science society},
  volume={1},
  pages={12},
  year={1986},
  organization={Amherst, MA}
}

@INPROCEEDINGS{nnlm:2001:nips,
    author = {Bengio, Yoshua and Ducharme, R{\'{e}}jean and Vincent, Pascal},
     title = {A Neural Probabilistic Language Model},
      year = {2001},
       url = {http://www.iro.umontreal.ca/~lisa/pointeurs/nips00_lm.ps},
}


@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}

%% Even newer NMT stuff, rare word
@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

%% Attention mechanism increased performance
@article{luong2015effective,
  title={Effective approaches to attention-based neural machine translation},
  author={Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  journal={arXiv preprint arXiv:1508.04025},
  year={2015}
}

%% LSTM bias unit
@article{zaremba2015empirical,
  title={An empirical exploration of recurrent network architectures},
  author={Zaremba, Wojciech},
  year={2015}
}

%% General dropout
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting.},
  author={Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014}
}

%% Better RNN dropout
@inproceedings{gal2016theoretically,
  title={A theoretically grounded application of dropout in recurrent neural networks},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1019--1027},
  year={2016}
}

%% Attention
@article{hsu2016recurrent,
  title={Recurrent Neural Network Encoder with Attention for Community Question Answering},
  author={Hsu, Wei-Ning and Zhang, Yu and Glass, James},
  journal={arXiv preprint arXiv:1603.07044},
  year={2016}
}

%% New attention
@article{sankaran2016temporal,
  title={Temporal attention model for neural machine translation},
  author={Sankaran, Baskaran and Mi, Haitao and Al-Onaizan, Yaser and Ittycheriah, Abe},
  journal={arXiv preprint arXiv:1608.02927},
  year={2016}
}

%% EncDec architecture
@inproceedings{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1171--1179},
  year={2015}
}

%% TF attention mechanism
@inproceedings{vinyals2015grammar,
  title={Grammar as a foreign language},
  author={Vinyals, Oriol and Kaiser, {\L}ukasz and Koo, Terry and Petrov, Slav and Sutskever, Ilya and Hinton, Geoffrey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2773--2781},
  year={2015}
}

%% LSTM weigth init
@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks.},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Aistats},
  volume={9},
  pages={249--256},
  year={2010}
}

%% Adam Optimzer implementation
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

%% AdaDelta
@article{cho2014properties,
  title={On the properties of neural machine translation: Encoder-decoder approaches},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.1259},
  year={2014}
}

%% Optimizer
@article{arik2017deep,
  title={Deep Voice: Real-time neural text-to-speech},
  author={Arik, Sercan O and Chrzanowski, Mike and Coates, Adam and Diamos, Gregory and Gibiansky, Andrew and Kang, Yongguo and Li, Xian and Miller, John and Raiman, Jonathan and Sengupta, Shubho and others},
  journal={arXiv preprint arXiv:1702.07825},
  year={2017}
}

%% Ada delta implementation
@article{zeiler2012adadelta,
  title={ADADELTA: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

@article{13833942,
    author = {Tieleman, T. and Hinton, G.},
    title = {{RMSprop Gradient Optimization}},
    year={2012},
    url = {http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf}
}

%% Open source Google stuff, talks about LSTMs vs GRU and embedding sizes
@ARTICLE{britz2017massive,
  author          = {{Britz}, Denny and {Goldie}, Anna and {Luong}, Thang and {Le}, Quoc},
  title           = "{Massive Exploration of Neural Machine Translation Architectures}",
  journal         = {ArXiv e-prints},
  archivePrefix   = "arXiv",
  eprinttype      = {arxiv},
  eprint          = {1703.03906},
  primaryClass    = "cs.CL",
  keywords        = {Computer Science - Computation and Language},
  year            = 2017,
  month           = mar,
}

@online{wikipedia2008scanner,
 author  = "Wikimedia Commons",
 title   = "A book scanner at the Internet Archive headquarters in San Francisco, California.",
 year    = "2008",
 urlseen = "25-05-17",
 url     = "https://upload.wikimedia.org/wikipedia/commons/6/65/Internet_Archive_book_scanner_1.jpg",
 note    = "File: \ttfamily{Internet Archive book scanner 1.jpg}",
}